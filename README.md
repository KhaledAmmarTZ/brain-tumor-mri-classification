# ğŸ§  Brain Tumor MRI Classification  
### *Custom CNN, VGG16, ResNet50 & DenseNet121 (Fine-Tuned)*

This project implements **binary classification (Tumor vs. No Tumor)** using four deep-learning models:

- **Custom CNN (Baseline Model)**
- **VGG16 â€“ Fine-Tuned**
- **ResNet50 â€“ Fine-Tuned**
- **DenseNet121 â€“ Fine-Tuned (Best Performing Model)**

The models are trained and evaluated on a curated brain MRI dataset containing **8,277 training images** and **1,816 testing images**, organized into *Tumor* and *No Tumor* classes.

This repository includes complete training notebooks, evaluation scripts, confusion matrix generation, saved model weights, and single-image inference support.

---

# ğŸ“˜ Google Colab Training Notebook  
Paste your notebook link here:

ğŸ”— **Colab Notebook:**  
https://colab.research.google.com/YOUR_LINK_HERE

(Required by instructor)

---

# ğŸ“‚ Dataset Structure  

Dataset must be arranged as follows:

BrainTumor/
Training/
Tumor/
No_Tumor/
Testing/
Tumor/
No_Tumor/

yaml
Copy code

Dataset Source (Mendeley DOI): **10.17632/c9rt8d6zrf.1**

---

# ğŸ—ï¸ Project Structure  

BrainTumor-MRI-Classification/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ Custom_CNN.ipynb
â”‚ â”œâ”€â”€ VGG16_FineTuned.ipynb
â”‚ â”œâ”€â”€ ResNet50_FineTuned.ipynb
â”‚ â”œâ”€â”€ DenseNet121_FineTuned.ipynb
â”‚
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ custom_cnn.h5
â”‚ â”œâ”€â”€ vgg16_finetuned.h5
â”‚ â”œâ”€â”€ resnet50_finetuned.h5
â”‚ â””â”€â”€ densenet121_finetuned.h5
â”‚
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ dataset_inspector.py
â”‚ â”œâ”€â”€ inference_single_image.py
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â””â”€â”€ plot_training.py
â”‚
â”œâ”€â”€ sample_input/
â”‚ â””â”€â”€ brain_mri_sample.jpg
â”‚
â””â”€â”€ sample_output/
â”œâ”€â”€ accuracy_curve.png
â”œâ”€â”€ loss_curve.png
â””â”€â”€ confusion_matrix.png

yaml
Copy code

---

# ğŸ§ª Models Used

## 1ï¸âƒ£ Custom CNN (Baseline)

```python
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])
2ï¸âƒ£ VGG16 (Fine-Tuned)
python
Copy code
base = VGG16(weights="imagenet", include_top=False, input_shape=(224,224,3))
base.trainable = False

x = Flatten()(base.output)
x = Dense(256, activation="relu")(x)
x = Dropout(0.5)(x)
out = Dense(1, activation="sigmoid")(x)

model = Model(base.input, out)
model.compile(optimizer=Adam(1e-4), loss="binary_crossentropy", metrics=["accuracy"])

# Unfreeze last 5 layers
for layer in base.layers[-5:]:
    layer.trainable = True
    
model.compile(optimizer=Adam(1e-5), loss="binary_crossentropy", metrics=["accuracy"])
3ï¸âƒ£ ResNet50 (Fine-Tuned)
python
Copy code
base = ResNet50(weights="imagenet", include_top=False, input_shape=(224,224,3))
base.trainable = False

x = GlobalAveragePooling2D()(base.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.4)(x)
out = Dense(1, activation='sigmoid')(x)

model = Model(base.input, out)
model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])

# Fine-tune last 30 layers
for layer in base.layers[-30:]:
    layer.trainable = True

model.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])
4ï¸âƒ£ DenseNet121 (Fine-Tuned) â€” â­ Best Model
python
Copy code
base = DenseNet121(weights="imagenet", include_top=False, input_shape=(224,224,3))
base.trainable = False

x = GlobalAveragePooling2D()(base.output)
x = Dense(256, activation="relu")(x)
x = Dropout(0.4)(x)
out = Dense(1, activation="sigmoid")(x)

model = Model(base.input, out)
model.compile(optimizer=Adam(1e-4), loss="binary_crossentropy", metrics=["accuracy"])

# Fine-tune last 40 layers
for layer in base.layers[-40:]:
    layer.trainable = True

model.compile(optimizer=Adam(1e-5), loss="binary_crossentropy", metrics=["accuracy"])
ğŸ“Š Evaluation Code (Accuracy, Loss & Confusion Matrix)
python
Copy code
loss, acc = model.evaluate(test_gen)
print("Test Accuracy:", acc)
print("Test Loss:", loss)

y_true = test_gen.classes
y_pred = (model.predict(test_gen) > 0.5).astype(int)

cm = confusion_matrix(y_true, y_pred)
print(classification_report(y_true, y_pred, target_names=["No Tumor", "Tumor"]))
ğŸ” Single-Image Prediction
python
Copy code
img = cv2.imread("sample.jpg")
img = cv2.resize(img, (224,224))
img = img / 255.0
img = np.expand_dims(img, axis=0)

pred = model.predict(img)[0][0]
print("Tumor" if pred > 0.5 else "No Tumor")
ğŸ“ Results Summary
Model	Accuracy	Comment
DenseNet121	â­ Highest	Best overall performance
ResNet50	High	Strong generalization
VGG16	Medium	Useful baseline TL model
Custom CNN	Lower	Good baseline benchmark

DenseNet121 performed the best across all metrics.

ğŸ¥ Presentation Demo (Required)
Add your project presentation video link here:

ğŸ”— https://your-video-link-here


